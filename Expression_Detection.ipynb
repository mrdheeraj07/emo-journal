{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "feB_jknhucsG"
   },
   "source": [
    "**DATASET**\n",
    "\n",
    "The both training and evaluation operations would be handled with [Fec2013](https://www.kaggle.com/c/challenges-in-representation-learning-facial-expression-recognition-challenge/data) dataset. Compressed version of the dataset takes 92 MB space whereas uncompressed version takes 295 MB space. There are 28K training and 3K testing images in the dataset. Each image was stored as 48×48 pixel. The pure dataset consists of image pixels (48×48=2304 values), emotion of each image and usage type (as train or test instance)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1125
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 14049224,
     "status": "ok",
     "timestamp": 1551106846344,
     "user": {
      "displayName": "Ritesh Kumar Maurya",
      "photoUrl": "https://lh3.googleusercontent.com/-TmfMp-FTfGw/AAAAAAAAAAI/AAAAAAAABjY/Hf-MlUKYkJQ/s64/photo.jpg",
      "userId": "15535582066412091985"
     },
     "user_tz": -330
    },
    "id": "1vj-nSTTkO9T",
    "outputId": "ab16a527-f761-4b31-d61b-24e1866ff151"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, AveragePooling2D\n",
    "from keras.layers import Dense, Activation, Dropout, Flatten\n",
    "\n",
    "from keras.preprocessing import image\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#------------------------------\n",
    "#cpu - gpu configuration\n",
    "#config = tf.ConfigProto( device_count = {'GPU': 0 , 'CPU': 56} ) #max: 1 gpu, 56 cpu\n",
    "#sess = tf.Session(config=config) \n",
    "#keras.backend.set_session(sess)\n",
    "#------------------------------\n",
    "#variables\n",
    "num_classes = 7 #angry, disgust, fear, happy, sad, surprise, neutral\n",
    "batch_size = 256\n",
    "epochs = 30\n",
    "#------------------------------\n",
    "#read kaggle facial expression recognition challenge dataset (fer2013.csv)\n",
    "#https://www.kaggle.com/c/challenges-in-representation-learning-facial-expression-recognition-challenge\n",
    "\n",
    "with open(\"fer2013.csv\") as f:\n",
    "  content = f.readlines()\n",
    "\n",
    "lines = np.array(content)\n",
    "\n",
    "num_of_instances = lines.size\n",
    "print(\"number of instances: \",num_of_instances)\n",
    "print(\"instance length: \",len(lines[1].split(\",\")[1].split(\" \")))\n",
    "\n",
    "#------------------------------\n",
    "#initialize trainset and test set\n",
    "x_train, y_train, x_test, y_test = [], [], [], []\n",
    "\n",
    "#------------------------------\n",
    "#transfer train and test set data\n",
    "for i in range(1,num_of_instances):\n",
    "    try:\n",
    "        emotion, img, usage = lines[i].split(\",\")\n",
    "          \n",
    "        val = img.split(\" \")\n",
    "            \n",
    "        pixels = np.array(val, 'float32')\n",
    "        \n",
    "        emotion = keras.utils.to_categorical(emotion, num_classes)\n",
    "    \n",
    "        if 'Training' in usage:\n",
    "            y_train.append(emotion)\n",
    "            x_train.append(pixels)\n",
    "        elif 'PublicTest' in usage:\n",
    "            y_test.append(emotion)\n",
    "            x_test.append(pixels)\n",
    "    except:\n",
    "      print(\"\", end=\"\")\n",
    "\n",
    "#------------------------------\n",
    "#data transformation for train and test sets\n",
    "x_train = np.array(x_train, 'float32')\n",
    "y_train = np.array(y_train, 'float32')\n",
    "x_test = np.array(x_test, 'float32')\n",
    "y_test = np.array(y_test, 'float32')\n",
    "\n",
    "x_train /= 255 #normalize inputs between [0, 1]\n",
    "x_test /= 255\n",
    "\n",
    "x_train = x_train.reshape(x_train.shape[0], 48, 48, 1)\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.reshape(x_test.shape[0], 48, 48, 1)\n",
    "x_test = x_test.astype('float32')\n",
    "\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')\n",
    "#------------------------------\n",
    "#construct CNN structure\n",
    "model = Sequential()\n",
    "\n",
    "#1st convolution layer\n",
    "model.add(Conv2D(64, (5, 5), activation='relu', input_shape=(48,48,1)))\n",
    "model.add(MaxPooling2D(pool_size=(5,5), strides=(2, 2)))\n",
    "\n",
    "#2nd convolution layer\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(AveragePooling2D(pool_size=(3,3), strides=(2, 2)))\n",
    "\n",
    "#3rd convolution layer\n",
    "model.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "model.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "model.add(AveragePooling2D(pool_size=(3,3), strides=(2, 2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "#fully connected neural networks\n",
    "model.add(Dense(1024, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(1024, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "#------------------------------\n",
    "#batch process\n",
    "gen = ImageDataGenerator()\n",
    "train_generator = gen.flow(x_train, y_train, batch_size=batch_size)\n",
    "\n",
    "#------------------------------\n",
    "\n",
    "model.compile(loss='categorical_crossentropy'\n",
    "    , optimizer=keras.optimizers.Adam()\n",
    "    , metrics=['accuracy']\n",
    ")\n",
    "\n",
    "#------------------------------\n",
    "\n",
    "fit = True\n",
    "\n",
    "if fit == True:\n",
    "\t#model.fit_generator(x_train, y_train, epochs=epochs) #train for all trainset\n",
    "\tmodel.fit_generator(train_generator, steps_per_epoch=batch_size, epochs=epochs) #train for randomly selected one\n",
    "else:\n",
    "\tmodel.load_weights('/data/facial_expression_model_weights.h5') #load weights\n",
    "\t\n",
    "#------------------------------\n",
    "\"\"\"\n",
    "#overall evaluation\n",
    "score = model.evaluate(x_test, y_test)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', 100*score[1])\n",
    "\"\"\"\n",
    "#------------------------------\n",
    "#function for drawing bar chart for emotion preditions\n",
    "def emotion_analysis(emotions):\n",
    "    objects = ('angry', 'disgust', 'fear', 'happy', 'sad', 'surprise', 'neutral')\n",
    "    y_pos = np.arange(len(objects))\n",
    "    \n",
    "    plt.bar(y_pos, emotions, align='center', alpha=0.5)\n",
    "    plt.xticks(y_pos, objects)\n",
    "    plt.ylabel('percentage')\n",
    "    plt.title('emotion')\n",
    "    \n",
    "    plt.show()\n",
    "#------------------------------\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "udLyFoZ7XiW9"
   },
   "outputs": [],
   "source": [
    "#Saving the model\n",
    "model.save('model25.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 73788,
     "status": "ok",
     "timestamp": 1551109897057,
     "user": {
      "displayName": "Ritesh Kumar Maurya",
      "photoUrl": "https://lh3.googleusercontent.com/-TmfMp-FTfGw/AAAAAAAAAAI/AAAAAAAABjY/Hf-MlUKYkJQ/s64/photo.jpg",
      "userId": "15535582066412091985"
     },
     "user_tz": -330
    },
    "id": "cvD0N40JooRh",
    "outputId": "0d266fec-dac0-4f8c-dc87-7468a0872b3f"
   },
   "outputs": [],
   "source": [
    "#Evaluation\n",
    "train_score = model.evaluate(x_train, y_train, verbose=0)\n",
    "print('Train loss:', train_score[0])\n",
    "print('Train accuracy:', 100*train_score[1])\n",
    " \n",
    "test_score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', test_score[0])\n",
    "print('Test accuracy:', 100*test_score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 136
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3945,
     "status": "ok",
     "timestamp": 1551110053547,
     "user": {
      "displayName": "Ritesh Kumar Maurya",
      "photoUrl": "https://lh3.googleusercontent.com/-TmfMp-FTfGw/AAAAAAAAAAI/AAAAAAAABjY/Hf-MlUKYkJQ/s64/photo.jpg",
      "userId": "15535582066412091985"
     },
     "user_tz": -330
    },
    "id": "0Fzu0U8cXHaq",
    "outputId": "2c4dbe13-ebec-4d14-ad84-754c5dcaedf7"
   },
   "outputs": [],
   "source": [
    "#Confusion Matrix.\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    " \n",
    "pred_list = []; actual_list = []\n",
    " \n",
    "for i in predictions:\n",
    " \n",
    "  pred_list.append(np.argmax(i))\n",
    " \n",
    "for i in y_test:\n",
    " \n",
    "  actual_list.append(np.argmax(i))\n",
    " \n",
    "confusion_matrix(actual_list, pred_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KJsn2kYUPSfn"
   },
   "outputs": [],
   "source": [
    "monitor_testset_results = True\n",
    "\n",
    "if monitor_testset_results == True:\n",
    "\t#make predictions for test set\n",
    "\tpredictions = model.predict(x_test)\n",
    "\n",
    "\tindex = 0\n",
    "\tfor i in predictions:\n",
    "\t\tif index < 30 and index >= 20:\n",
    "\t\t\t#print(i) #predicted scores\n",
    "\t\t\t#print(y_test[index]) #actual scores\n",
    "\t\t\t\n",
    "\t\t\ttesting_img = np.array(x_test[index], 'float32')\n",
    "\t\t\ttesting_img = testing_img.reshape([48, 48]);\n",
    "\t\t\t\n",
    "\t\t\tplt.gray()\n",
    "\t\t\tplt.imshow(testing_img)\n",
    "\t\t\tplt.show()\n",
    "\t\t\t\n",
    "\t\t\tprint(i)\n",
    "\t\t\t\n",
    "\t\t\temotion_analysis(i)\n",
    "\t\t\tprint(\"----------------------------------------------\")\n",
    "\t\tindex = index + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 207
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 6372,
     "status": "ok",
     "timestamp": 1551253200973,
     "user": {
      "displayName": "Ritesh Kumar Maurya",
      "photoUrl": "https://lh3.googleusercontent.com/-TmfMp-FTfGw/AAAAAAAAAAI/AAAAAAAABjY/Hf-MlUKYkJQ/s64/photo.jpg",
      "userId": "15535582066412091985"
     },
     "user_tz": -330
    },
    "id": "hO8sWmgJgTf1",
    "outputId": "507e4c6d-ba7d-4352-d3c6-0d2425d7ea6d"
   },
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "model = load_model('model25.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FtgHdvjEmf5S"
   },
   "outputs": [],
   "source": [
    "def emotion_analysis(emotions):\n",
    "    objects = ('angry', 'disgust', 'fear', 'happy', 'sad', 'surprise', 'neutral')\n",
    "    y_pos = np.arange(len(objects))\n",
    "    \n",
    "    plt.bar(y_pos, emotions, align='center', alpha=0.5)\n",
    "    plt.xticks(y_pos, objects)\n",
    "    plt.ylabel('percentage')\n",
    "    plt.title('emotion')\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 750
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2506,
     "status": "ok",
     "timestamp": 1551255177015,
     "user": {
      "displayName": "Ritesh Kumar Maurya",
      "photoUrl": "https://lh3.googleusercontent.com/-TmfMp-FTfGw/AAAAAAAAAAI/AAAAAAAABjY/Hf-MlUKYkJQ/s64/photo.jpg",
      "userId": "15535582066412091985"
     },
     "user_tz": -330
    },
    "id": "9ZIlpvu1cHMk",
    "outputId": "47bf3b70-a7ea-4a1e-e698-edd0cab06899"
   },
   "outputs": [],
   "source": [
    "#Testing a file.\n",
    "\n",
    "from keras.preprocessing import image\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "file = 'photo.jpg'\n",
    "true_image = image.load_img(file)\n",
    "img = image.load_img(file, grayscale=True, target_size=(48, 48))\n",
    "\n",
    "x = image.img_to_array(img)\n",
    "x = np.expand_dims(x, axis = 0)\n",
    "\n",
    "x /= 255\n",
    "\n",
    "custom = model.predict(x)\n",
    "emotion_analysis(custom[0])\n",
    "\n",
    "x = np.array(x, 'float32')\n",
    "x = x.reshape([48, 48]);\n",
    "\n",
    "plt.gray()\n",
    "plt.imshow(true_image)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QMyrDnhWX_Zj"
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "            \n",
    "def facecrop(image):  \n",
    "    facedata = \"haarcascade_frontalface_default.xml\"\n",
    "    cascade = cv2.CascadeClassifier(facedata)\n",
    "\n",
    "    img = cv2.imread(image)\n",
    "\n",
    "    try:\n",
    "    \n",
    "        minisize = (img.shape[1],img.shape[0])\n",
    "        miniframe = cv2.resize(img, minisize)\n",
    "\n",
    "        faces = cascade.detectMultiScale(miniframe)\n",
    "\n",
    "        for f in faces:\n",
    "            x, y, w, h = [ v for v in f ]\n",
    "            cv2.rectangle(img, (x,y), (x+w,y+h), (0,255,0), 2)\n",
    "\n",
    "            sub_face = img[y:y+h, x:x+w]\n",
    "\n",
    "            \n",
    "            cv2.imwrite('capture.jpg', sub_face)\n",
    "            #print (\"Writing: \" + image)\n",
    "\n",
    "    except Exception as e:\n",
    "        print (e)\n",
    "\n",
    "    #cv2.imshow(image, img)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    facecrop('1.jpg')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Je1qP-gpUJSU"
   },
   "outputs": [],
   "source": [
    "#CODE for Capturing an image on Colab from here: https://colab.research.google.com/notebook#fileId=1OnUy6eFE7XhdfGfAHDCqQxpwueTOj_NO\n",
    "\n",
    "from IPython.display import display, Javascript\n",
    "from google.colab.output import eval_js\n",
    "from base64 import b64decode\n",
    "\n",
    "def take_photo(filename='photo.jpg', quality=0.8):\n",
    "  js = Javascript('''\n",
    "    async function takePhoto(quality) {\n",
    "      const div = document.createElement('div');\n",
    "      const capture = document.createElement('button');\n",
    "      capture.textContent = 'Capture';\n",
    "      div.appendChild(capture);\n",
    "\n",
    "      const video = document.createElement('video');\n",
    "      video.style.display = 'block';\n",
    "      const stream = await navigator.mediaDevices.getUserMedia({video: true});\n",
    "\n",
    "      document.body.appendChild(div);\n",
    "      div.appendChild(video);\n",
    "      video.srcObject = stream;\n",
    "      await video.play();\n",
    "\n",
    "      // Resize the output to fit the video element.\n",
    "      google.colab.output.setIframeHeight(document.documentElement.scrollHeight, true);\n",
    "\n",
    "      // Wait for Capture to be clicked.\n",
    "      await new Promise((resolve) => capture.onclick = resolve);\n",
    "\n",
    "      const canvas = document.createElement('canvas');\n",
    "      canvas.width = video.videoWidth;\n",
    "      canvas.height = video.videoHeight;\n",
    "      canvas.getContext('2d').drawImage(video, 0, 0);\n",
    "      stream.getVideoTracks()[0].stop();\n",
    "      div.remove();\n",
    "      return canvas.toDataURL('image/jpeg', quality);\n",
    "    }\n",
    "    ''')\n",
    "  display(js)\n",
    "  data = eval_js('takePhoto({})'.format(quality))\n",
    "  binary = b64decode(data.split(',')[1])\n",
    "  with open(filename, 'wb') as f:\n",
    "    f.write(binary)\n",
    "  return filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 11595,
     "status": "ok",
     "timestamp": 1551255166693,
     "user": {
      "displayName": "Ritesh Kumar Maurya",
      "photoUrl": "https://lh3.googleusercontent.com/-TmfMp-FTfGw/AAAAAAAAAAI/AAAAAAAABjY/Hf-MlUKYkJQ/s64/photo.jpg",
      "userId": "15535582066412091985"
     },
     "user_tz": -330
    },
    "id": "xv63Tmy-weJ4",
    "outputId": "80e4b88d-7cb6-4dc3-897b-aa4907205e60"
   },
   "outputs": [],
   "source": [
    "take_photo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "Expression_Detection.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
